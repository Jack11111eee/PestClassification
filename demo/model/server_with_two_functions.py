import os
import io
import uuid
import threading
import torch
import shutil
import torchvision.transforms as T
from torchvision import datasets
from torch.utils.data import DataLoader, ConcatDataset, Dataset
from torchvision.models import resnet50
from flask import Flask, request, jsonify
from PIL import Image
import time
import sys
import base64
import numpy as np
import cv2

# å°è¯•å¯¼å…¥ GPU ç›‘æ§åº“ (å¦‚æœå®‰è£…å¤±è´¥ä¹Ÿä¸å½±å“ä¸»ç¨‹åºè¿è¡Œ)
try:
    import pynvml
    pynvml.nvmlInit()
    HAS_GPU_MONITOR = True
except Exception as e:
    HAS_GPU_MONITOR = False
    print(f"âš ï¸ GPU Monitor disabled (nvidia-ml-py3 not found): {e}")

# ================= 1. å…¨å±€é…ç½® =================
BASE_DIR = '/home/hzcu/repo/modelStaff'
# æƒé‡è·¯å¾„
MODEL_PATH = os.path.join(BASE_DIR, 'ResNet50_v1.pth')      
BEST_MODEL_PATH = os.path.join(BASE_DIR, 'ResNet50_best.pth') 
# æ•°æ®è·¯å¾„
FEEDBACK_DIR = os.path.join(BASE_DIR, 'feedback_data')        
ARCHIVE_DIR = os.path.join(BASE_DIR, 'archived_feedback')     
ORIGINAL_DATASET_DIR = '/home/hzcu/PlantDiseases_Final_Split' 

RETRAIN_THRESHOLD = 1000
PORT = 5003  # ä¿æŒåŸç«¯å£ï¼Œå¯¹æ¥åç«¯
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

TASKS_DB = {}  # å…¨å±€å­—å…¸ï¼Œç”¨äºå­˜å‚¨æ‰¹é‡ä»»åŠ¡çš„çŠ¶æ€

# ç±»åˆ«å®šä¹‰ (å¿…é¡»ä¸è®­ç»ƒæ—¶ä¸¥æ ¼ä¸€è‡´)
raw_classes = [
    'Apple_Black_Rot', 'Apple_Cedar_Apple_Rust', 'Apple_healthy', 'Apple_Scab', 
    'Blueberry_healthy', 'Cherry_healthy', 'Cherry_Powdery_Mildew', 
    'Corn_Common_Rust', 'Corn_Gray_Leaf_Spot', 'Corn_healthy', 
    'Corn_Northern_Leaf_Blight', 'Grape_Black_Rot', 'Grape_Esca_Black_Measles', 
    'Grape_healthy', 'Grape_Leaf_Blight_Isariopsis', 'Orange_Haunglongbing_Citrus_Greening', 
    'Peach_Bacterial_Spot', 'Peach_healthy', 'Pepper_Bell_Bacterial_Spot', 
    'Pepper_Bell_healthy', 'Potato_Early_Blight', 'Potato_healthy', 
    'Potato_Late_Blight', 'Raspberry_healthy', 'Soybean_healthy', 
    'Squash_Powdery_Mildew', 'Strawberry_healthy', 'Strawberry_Leaf_Scorch', 
    'Tomato_Bacterial_Spot', 'Tomato_Early_Blight', 'Tomato_healthy', 
    'Tomato_Late_Blight', 'Tomato_Leaf_Mold', 'Tomato_Mosaic_Virus', 
    'Tomato_Septoria_Leaf_Spot', 'Tomato_Target_Spot', 'Tomato_Two_Spotted_Spider_Mite', 
    'Tomato_Yellow_Leaf_Curl_Virus', 'Wheat_Crown_and_Root_Rot', 'Wheat_healthy', 
    'Wheat_Leaf_Rust', 'Wheat_Loose_Smut'
]
CLASS_NAMES = sorted(raw_classes)
NUM_CLASSES = len(CLASS_NAMES)

IS_TRAINING = False 

app = Flask(__name__)

# ================= 2. æ¨¡å‹ç»“æ„ä¸åŠ è½½ =================

def load_network_structure():
    """æ„é€ resnet50å¹¶åœ¨æœ€åå…¨è¿æ¥å±‚åŒ¹é…ç±»åˆ«æ•°"""
    net = resnet50(weights=None)
    num_ftrs = net.fc.in_features
    net.fc = torch.nn.Linear(num_ftrs, NUM_CLASSES)
    return net

def init_model():
    """åˆå§‹åŒ–æ¨¡å‹åŠ è½½ï¼Œå¦‚æœæƒé‡åŠ è½½å¤±è´¥ç›´æ¥åœæ­¢ç¨‹åº"""
    net = load_network_structure()
    
    # ä¼˜å…ˆåŠ è½½é‡è®­ç»ƒåçš„æœ€ä¼˜æ¨¡å‹ï¼Œå¦åˆ™åŠ è½½åˆå§‹æ¨¡å‹
    if os.path.exists(BEST_MODEL_PATH):
        weights_to_load = BEST_MODEL_PATH
        print(f"ğŸ“ˆ å‘ç°é‡è®­ç»ƒæƒé‡: {BEST_MODEL_PATH}")
    else:
        weights_to_load = MODEL_PATH
        print(f"ğŸ“¦ åŠ è½½åˆå§‹æƒé‡: {MODEL_PATH}")

    if not os.path.exists(weights_to_load):
        print(f"âŒ ä¸¥é‡é”™è¯¯: æ‰¾ä¸åˆ°ä»»ä½•æƒé‡æ–‡ä»¶äº {weights_to_load}")
        sys.exit(1)

    try:
        # strict=True ä¿è¯ç½‘ç»œå±‚å¿…é¡»å®Œå…¨åŒ¹é…
        state_dict = torch.load(weights_to_load, map_location=DEVICE)
        net.load_state_dict(state_dict, strict=True)
        net.to(DEVICE)
        net.eval()
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼å½“å‰è®¾å¤‡: {DEVICE}")
        return net
    except Exception as e:
        print(f"ğŸš¨ æƒé‡åŠ è½½å¤±è´¥(å¯èƒ½æ˜¯ç±»åˆ«æ•°ä¸åŒ¹é…): {e}")
        sys.exit(1)

# å…¨å±€åˆå§‹åŒ–
model = init_model()

# é¢„å¤„ç†ä¿æŒä¸è®­ç»ƒä¸€è‡´ (ImageNetæ ‡å‡†)
inference_transform = T.Compose([
    T.Resize(256),
    T.CenterCrop(224),
    T.ToTensor(),
    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

train_transform = T.Compose([
    T.RandomResizedCrop(224),
    T.RandomHorizontalFlip(),
    T.ToTensor(),
    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# ================= Grad-CAM è¾…åŠ©å‡½æ•° =================
def generate_gradcam(model, input_tensor, predicted_class):
    """ç”Ÿæˆ Grad-CAM çƒ­åŠ›å›¾"""
    # è·å–æœ€åä¸€ä¸ªå·ç§¯å±‚çš„è¾“å‡º
    final_conv_layer = model.layer4[2]  # ResNet50 çš„æœ€åä¸€ä¸ªå·ç§¯å—

    # å­˜å‚¨æ¢¯åº¦å’Œæ¿€æ´»
    gradients = []
    activations = []

    def forward_hook(module, input, output):
        activations.append(output)

    def backward_hook(module, grad_input, grad_output):
        gradients.append(grad_output[0])

    # æ³¨å†Œé’©å­
    forward_handle = final_conv_layer.register_forward_hook(forward_hook)
    backward_handle = final_conv_layer.register_backward_hook(backward_hook)

    # å‰å‘ä¼ æ’­
    output = model(input_tensor)
    predicted_output = output[0, predicted_class]

    # åå‘ä¼ æ’­
    model.zero_grad()
    predicted_output.backward()

    # ç§»é™¤é’©å­
    forward_handle.remove()
    backward_handle.remove()

    # è·å–æ¢¯åº¦å’Œæ¿€æ´»
    gradients = gradients[0][0]  # gradients æ˜¯ batch_size x channels x h x w
    activations = activations[0][0]  # activations åŒä¸Š

    # è®¡ç®— Grad-CAM
    weights = torch.mean(gradients, dim=[1, 2])  # å…¨å±€å¹³å‡æ± åŒ–å¾—åˆ°æƒé‡
    cam = torch.zeros(activations.shape[-2:], dtype=torch.float32)

    for i, w in enumerate(weights):
        cam += w * activations[i]

    cam = torch.nn.functional.relu(cam)  # ReLU æ¿€æ´»
    cam = cam - cam.min()
    cam = cam / cam.max()
    cam = cam.cpu().data.numpy()

    return cv2.resize(cam, (224, 224))  # è°ƒæ•´åˆ°åŸå›¾å¤§å°

# ================= è¾…åŠ©å·¥å…·ï¼šGPU ç›‘æ§ =================
def get_gpu_usage():
    """ç®¡ç†å‘˜ä¸“ç”¨ï¼šè·å–GPUæ˜¾å­˜å’Œè´Ÿè½½"""
    if not HAS_GPU_MONITOR or DEVICE.type != 'cuda':
        return "GPU: N/A"
    try:
        handle = pynvml.nvmlDeviceGetHandleByIndex(0)
        mem_info = pynvml.nvmlDeviceGetMemoryInfo(handle)
        util = pynvml.nvmlDeviceGetUtilizationRates(handle)
        used_mb = mem_info.used // 1024**2
        total_mb = mem_info.total // 1024**2
        return f"GPU: {util.gpu}% | Mem: {used_mb}/{total_mb} MB"
    except:
        return "GPU: Err"

# ================= æ‰¹é‡å¤„ç†å·¥å…·ç±» =================
class ImageFolderDataset(Dataset):
    """è‡ªå®šä¹‰ Datasetï¼Œç”¨äºè¯»å–æ–‡ä»¶å¤¹ä¸­çš„å›¾ç‰‡"""
    def __init__(self, file_paths, transform):
        self.file_paths = file_paths
        self.transform = transform

    def __len__(self):
        return len(self.file_paths)

    def __getitem__(self, idx):
        path = self.file_paths[idx]
        try:
            image = Image.open(path).convert('RGB')
            return self.transform(image), path
        except Exception as e:
            print(f"âš ï¸ Reads error {path}: {e}")
            # è¿”å›ä¸€ä¸ªå…¨0çš„tensoré˜²æ­¢æŠ¥é”™ä¸­æ–­ï¼Œåç»­å¯ä»¥æ ¹æ®pathè¿‡æ»¤
            return torch.zeros((3, 224, 224)), "ERROR_FILE"

def run_batch_inference(task_id, folder_path):
    """åå°è¿è¡Œçš„æ‰¹é‡é¢„æµ‹é€»è¾‘ï¼ˆæ‰¹é‡é¢„æµ‹ä¸æ·»åŠ çƒ­åŠ›å›¾ï¼Œä»¥ä¿æŒæ€§èƒ½ï¼‰"""
    print(f"[{task_id}] Thread started for: {folder_path}")
    
    # 1. æ‰«ææ–‡ä»¶
    valid_exts = ('.jpg', '.jpeg', '.png', '.bmp')
    all_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.lower().endswith(valid_exts)]
    total = len(all_files)
    
    if total == 0:
        TASKS_DB[task_id]['status'] = 'failed'
        TASKS_DB[task_id]['error'] = 'No images found in folder'
        return

    # 2. ç­–ç•¥é€‰æ‹© (Q3éœ€æ±‚)
    batch_size = 32 if total >= 50 else 1
    num_workers = 4 if os.cpu_count() > 4 else 0
    
    print(f"[{task_id}] Strategy: Total={total}, BatchSize={batch_size}")

    dataset = ImageFolderDataset(all_files, inference_transform)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)

    TASKS_DB[task_id].update({'total': total, 'processed': 0, 'status': 'processing'})
    
    results = []
    start_time = time.time()

    # 3. å¼€å§‹é¢„æµ‹
    with torch.no_grad():
        for batch_imgs, batch_paths in dataloader:
            batch_imgs = batch_imgs.to(DEVICE)
            
            outputs = model(batch_imgs)
            probs = torch.nn.functional.softmax(outputs, dim=1)
            confidences, preds = torch.max(probs, 1)
            
            # å¤„ç†è¿™ä¸€ä¸ª Batch çš„ç»“æœ
            current_batch_results = []
            for i in range(len(batch_paths)):
                path = batch_paths[i]
                if path == "ERROR_FILE": continue # è·³è¿‡æŸåå›¾ç‰‡

                idx = preds[i].item()
                conf = confidences[i].item()
                
                res = {
                    "filename": os.path.basename(path),
                    "class_name": CLASS_NAMES[idx],
                    "confidence": float(f"{conf:.4f}")
                }
                current_batch_results.append(res)
            
            results.extend(current_batch_results)
            
            # æ›´æ–°å…¨å±€è¿›åº¦
            processed = len(results)
            elapsed = time.time() - start_time
            avg_per_img = elapsed / processed if processed > 0 else 0
            eta = (total - processed) * avg_per_img
            
            TASKS_DB[task_id].update({
                'processed': processed,
                'progress_percent': int((processed / total) * 100),
                'eta_seconds': int(eta),
                'avg_latency_ms': int(avg_per_img * 1000)
            })
            
            # ç®¡ç†å‘˜æ—¥å¿— (Q1 & Q4)
            gpu_log = get_gpu_usage()
            print(f"[{task_id}] {processed}/{total} ({int(processed/total*100)}%) | ETA: {int(eta)}s | {gpu_log}")

    # 4. å®Œæˆ
    TASKS_DB[task_id]['status'] = 'completed'
    TASKS_DB[task_id]['results'] = results # è¿™é‡Œå­˜äº†æ‰€æœ‰ç»“æœ
    # æ³¨æ„ï¼šå¦‚æœ results æå¤§(å‡ åä¸‡æ¡)ï¼Œå»ºè®®ç›´æ¥å†™å…¥ json æ–‡ä»¶åˆ°ç¡¬ç›˜ï¼Œè€Œä¸æ˜¯å­˜åœ¨å†…å­˜é‡Œ
    print(f"[{task_id}] Finished in {int(time.time() - start_time)}s")


# ================= 3. è¾…åŠ©åŠŸèƒ½ =================

def get_feedback_count():
    count = 0
    for root, dirs, files in os.walk(FEEDBACK_DIR):
        count += len([f for f in files if f.endswith(('.jpg', '.png', '.jpeg'))])
    return count

def train_task_thread():
    global IS_TRAINING, model
    print("\nğŸš€ åå°è®­ç»ƒä»»åŠ¡å¼€å§‹...")
    IS_TRAINING = True
    
    try:
        # A. æ£€æŸ¥æ•°æ®
        if not os.path.exists(ORIGINAL_DATASET_DIR):
            print(f"âŒ é”™è¯¯: åŸå§‹è®­ç»ƒé›†ç›®å½•ä¸å­˜åœ¨ {ORIGINAL_DATASET_DIR}")
            return

        original_dataset = datasets.ImageFolder(ORIGINAL_DATASET_DIR, transform=train_transform)
        feedback_dataset = datasets.ImageFolder(FEEDBACK_DIR, transform=train_transform)
        combined_dataset = ConcatDataset([original_dataset, feedback_dataset])
        
        # å»ºè®® batch_size ä¸è¦å¤ªå¤§
        train_loader = DataLoader(combined_dataset, batch_size=32, shuffle=True, num_workers=4) 
        
        # B. å‡†å¤‡æ¨¡å‹ï¼ˆåœ¨å½“å‰æƒé‡åŸºç¡€ä¸Šç»§ç»­ç»ƒï¼‰
        new_model = load_network_structure()
        new_model.load_state_dict(model.state_dict())
        new_model.to(DEVICE)
        new_model.train()

        criterion = torch.nn.CrossEntropyLoss()
        optimizer = torch.optim.Adam(new_model.parameters(), lr=0.00001) # ç”¨æ›´å°çš„å­¦ä¹ ç‡é˜²æ­¢ç ´åæƒé‡

        EPOCHS = 3
        for epoch in range(EPOCHS):
            running_loss = 0.0
            for inputs, labels in train_loader:
                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)
                optimizer.zero_grad()
                outputs = new_model(inputs)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()
                running_loss += loss.item()
            print(f"   Epoch {epoch+1}/{EPOCHS} - Loss: {running_loss/len(train_loader):.4f}")

        # C. ä¿å­˜ä¸åŒæ­¥
        torch.save(new_model.state_dict(), BEST_MODEL_PATH)
        model.load_state_dict(new_model.state_dict())
        model.eval()

        # D. å½’æ¡£æ•°æ®
        archive_dest = os.path.join(ARCHIVE_DIR, str(int(time.time())))
        shutil.move(FEEDBACK_DIR, archive_dest)
        os.makedirs(FEEDBACK_DIR, exist_ok=True)
        print(f"ğŸ“¦ è®­ç»ƒå®Œæˆï¼Œæ¨¡å‹å·²æ›´æ–°ï¼Œåé¦ˆæ•°æ®å·²å½’æ¡£ã€‚")

    except Exception as e:
        print(f"âŒ è®­ç»ƒä»»åŠ¡å¤±è´¥: {e}")
    finally:
        IS_TRAINING = False

# ================= 4. API è·¯ç”± =================

@app.route('/health', methods=['GET'])
def health_check():
    return jsonify({"status": "up", "device": str(DEVICE), "mode": "Merged"})

@app.route('/predict', methods=['POST'])
def predict():
    if 'file' not in request.files: return jsonify({'error': 'No file'}), 400
    file = request.files['file']
    
    try:
        image = Image.open(io.BytesIO(file.read())).convert('RGB')
        
        # ä¿å­˜åŸå§‹å›¾åƒç”¨äºçƒ­åŠ›å›¾å åŠ 
        original_image = np.array(image.resize((224, 224)))  # ResNet è¾“å…¥æ˜¯ 224x224ï¼Œä½†åŸå›¾è°ƒæ•´ä¸ºåŒ¹é…
        
        img_tensor = inference_transform(image).unsqueeze(0).to(DEVICE)
        
        # å‰å‘ä¼ æ’­è®¡ç®—é¢„æµ‹
        outputs = model(img_tensor)
        probabilities = torch.nn.functional.softmax(outputs, dim=1)
        confidence, predicted_idx = torch.max(probabilities, 1)
        
        conf_score = confidence.item()
        result_class = CLASS_NAMES[predicted_idx.item()]
        
        # ä½ç½®ä¿¡åº¦æ‹¦æˆªï¼šå¦‚æœç½®ä¿¡åº¦ä½äº 0.6ï¼Œè¿”å›æ¨¡ç³Šç»“æœ
        if conf_score < 0.6:
            print(f"ğŸ” é¢„æµ‹ç»“æœ: ä½ç½®ä¿¡åº¦ - æ— æ³•ç¡®å®š (ç½®ä¿¡åº¦: {conf_score:.4f})")
            return jsonify({
                'prediction': {
                    'class_name': "æ— æ³•ç¡®å®š",
                    'confidence': float(f"{conf_score:.4f}")
                },
                'status': 'success',
                'explanation': {
                    'message': 'æ¨¡å‹é¢„æµ‹ç½®ä¿¡åº¦è¾ƒä½ï¼Œå»ºè®®é‡æ–°æ‹æ‘„æ›´æ¸…æ™°çš„å›¾åƒæˆ–å’¨è¯¢ä¸“å®¶ã€‚',
                    'suggested_actions': ['é‡æ–°æ‹æ‘„ç…§ç‰‡', 'ä½¿ç”¨æ”¾å¤§é•œ', 'æ±‚åŠ©å†œä¸šä¸“å®¶']
                }
            })
        
        # å¦‚æœç½®ä¿¡åº¦è¶³å¤Ÿé«˜ï¼Œåˆ™ç”Ÿæˆ Grad-CAM çƒ­åŠ›å›¾
        heat_map = generate_gradcam(model, img_tensor, predicted_idx.item())
        
        # å åŠ çƒ­åŠ›å›¾åˆ°åŸå›¾
        heat_map = cv2.applyColorMap(np.uint8(255 * heat_map), cv2.COLORMAP_JET)
        superimposed_image = cv2.addWeighted(heat_map, 0.4, original_image, 0.6, 0)
        
        # å°†å åŠ å›¾åƒè½¬æ¢ä¸º base64
        _, buffer = cv2.imencode('.jpg', superimposed_image)
        heatmap_base64 = base64.b64encode(buffer).decode('utf-8')
        
        print(f"ğŸ” é¢„æµ‹ç»“æœ: {result_class} (ç½®ä¿¡åº¦: {conf_score:.4f})")

        return jsonify({
            'prediction': {
                'class_name': result_class,
                'confidence': float(f"{conf_score:.4f}")
            },
            'status': 'success',
            'explanation': {
                'heatmap_image': f"data:image/jpeg;base64,{heatmap_base64}",
                'message': f'æ¨¡å‹ä¸»è¦å…³æ³¨å›¾åƒä¸­çš„é«˜äº®åŒºåŸŸæ¥è¯†åˆ«ä¸ºâ€œ{result_class}â€ã€‚',
                'suggested_actions': ['æ£€æŸ¥é«˜äº®åŒºåŸŸæ˜¯å¦æœ‰ç—…æ–‘', 'ç¡®è®¤ç¯å¢ƒä¸‹çŠ¶å†µ']
            }
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/feedback', methods=['POST'])
def save_feedback():
    if 'file' not in request.files or 'correct_label' not in request.form:
        return jsonify({"error": "Missing parameter"}), 400

    file = request.files['file']
    label = request.form['correct_label']
    
    if label not in CLASS_NAMES:
        return jsonify({"error": f"Invalid label: {label}"}), 400

    try:
        label_dir = os.path.join(FEEDBACK_DIR, label)
        os.makedirs(label_dir, exist_ok=True)
        file.save(os.path.join(label_dir, f"{uuid.uuid4()}.jpg"))
        
        count = get_feedback_count()
        return jsonify({
            "status": "success", 
            "current_count": count,
            "ready_to_train": count >= RETRAIN_THRESHOLD
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/retrain', methods=['POST'])
def manual_retrain():
    if IS_TRAINING: return jsonify({"error": "Training in progress"}), 409
    if get_feedback_count() == 0: return jsonify({"error": "No data"}), 400
    
    threading.Thread(target=train_task_thread).start()
    return jsonify({"message": "Retraining started"})

@app.route('/status', methods=['GET'])
def server_status():
    return jsonify({
        "is_training": IS_TRAINING,
        "feedback_count": get_feedback_count(),
        "ready_to_train": get_feedback_count() >= RETRAIN_THRESHOLD,
        "device": str(DEVICE)
    })

# --- æ–°å¢ï¼šæ‰¹é‡ä»»åŠ¡æ¥å£ ---
@app.route('/batch/start', methods=['POST'])
def start_batch_task():
    """Java ä¸Šä¼  Zip è§£å‹åï¼Œè°ƒç”¨æ­¤æ¥å£å¼€å§‹é¢„æµ‹"""
    data = request.json
    folder_path = data.get('folder_path')
    task_id = data.get('task_id')
    
    if not folder_path or not task_id:
        return jsonify({"error": "Missing folder_path or task_id"}), 400
    
    if not os.path.exists(folder_path):
        return jsonify({"error": "Folder does not exist"}), 404

    # åˆå§‹åŒ–çŠ¶æ€
    TASKS_DB[task_id] = {'status': 'pending', 'processed': 0, 'total': 0}
    
    # å¯åŠ¨åå°çº¿ç¨‹
    t = threading.Thread(target=run_batch_inference, args=(task_id, folder_path))
    t.start()
    
    return jsonify({"status": "started", "task_id": task_id})

@app.route('/batch/status/<task_id>', methods=['GET'])
def get_batch_status(task_id):
    """å‰ç«¯è½®è¯¢æ­¤æ¥å£è·å–è¿›åº¦æ¡"""
    task = TASKS_DB.get(task_id)
    if not task:
        return jsonify({"error": "Task not found"}), 404
        
    response = {
        "status": task['status'],
        "progress": task.get('progress_percent', 0),
        "metrics": {
            "processed": task.get('processed', 0),
            "total": task.get('total', 0),
            "eta_seconds": task.get('eta_seconds', 0),
            "avg_latency_ms": task.get('avg_latency_ms', 0)
        }
    }
    
    # åªæœ‰å½“ä»»åŠ¡å®Œæˆæ—¶ï¼Œæ‰è¿”å›ç»“æœæ•°æ® (é¿å…è½®è¯¢æ—¶ä¼ è¾“æ•°æ®è¿‡å¤§)
    if task['status'] == 'completed':
        response['results'] = task.get('results', [])
        
    return jsonify(response)

if __name__ == '__main__':
    os.makedirs(FEEDBACK_DIR, exist_ok=True)
    os.makedirs(ARCHIVE_DIR, exist_ok=True)
    print(f"ğŸš€ AI Server (Merged with Confidence Gate and Grad-CAM) è¿è¡Œäºç«¯å£ {PORT}...")
    app.run(host='0.0.0.0', port=PORT, debug=False, threaded=True)
