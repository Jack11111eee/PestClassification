# inference_server_with_retrain.py
import os
import io
import uuid
import threading
import torch
import shutil
import torchvision.transforms as T
from torchvision import datasets
from torch.utils.data import DataLoader, ConcatDataset
from torchvision.models import resnet50
from flask import Flask, request, jsonify
from PIL import Image
import time

# ================= 1. å…¨å±€é…ç½® =================
# åŸºç¡€è·¯å¾„
BASE_DIR = '/home/hzcu/repo/modelStaff'
MODEL_PATH = os.path.join(BASE_DIR, 'ResNet50_v1.pth')      # åˆå§‹æ¨¡å‹
BEST_MODEL_PATH = os.path.join(BASE_DIR, 'ResNet50_best.pth') # ç”¨äºä¿å­˜æ–°è®­ç»ƒçš„æœ€å¥½æ¨¡å‹
FEEDBACK_DIR = os.path.join(BASE_DIR, 'feedback_data')        # å¾…è®­ç»ƒæ•°æ®æ± 
ARCHIVE_DIR = os.path.join(BASE_DIR, 'archived_feedback')     # è®­ç»ƒå®Œå½’æ¡£çš„æ•°æ®

# å¿…é¡»æŒ‡å‘ä½ æœåŠ¡å™¨ä¸Šçš„åŸå§‹å¤§æ•°æ®é›†è·¯å¾„ (ç”¨äºé˜²æ­¢é—å¿˜æ—§çŸ¥è¯†)
ORIGINAL_DATASET_DIR = '/home/hzcu/PlantDiseases_Final_Split' 

# é˜ˆå€¼é…ç½®
RETRAIN_THRESHOLD = 5  # ä¸ºäº†æ–¹ä¾¿æµ‹è¯•ï¼Œå»ºè®®å…ˆè®¾ä¸º 5ã€‚æµ‹è¯•æ²¡é—®é¢˜åå†æ”¹æˆ 100
PORT = 5001
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ç±»åˆ«å®šä¹‰ (42ç±»)
raw_classes = [
    'Apple_Black_Rot', 'Apple_Cedar_Apple_Rust', 'Apple_healthy', 'Apple_Scab', 
    'Blueberry_healthy', 'Cherry_healthy', 'Cherry_Powdery_Mildew', 
    'Corn_Common_Rust', 'Corn_Gray_Leaf_Spot', 'Corn_healthy', 
    'Corn_Northern_Leaf_Blight', 'Grape_Black_Rot', 'Grape_Esca_Black_Measles', 
    'Grape_healthy', 'Grape_Leaf_Blight_Isariopsis', 'Orange_Haunglongbing_Citrus_Greening', 
    'Peach_Bacterial_Spot', 'Peach_healthy', 'Pepper_Bell_Bacterial_Spot', 
    'Pepper_Bell_healthy', 'Potato_Early_Blight', 'Potato_healthy', 
    'Potato_Late_Blight', 'Raspberry_healthy', 'Soybean_healthy', 
    'Squash_Powdery_Mildew', 'Strawberry_healthy', 'Strawberry_Leaf_Scorch', 
    'Tomato_Bacterial_Spot', 'Tomato_Early_Blight', 'Tomato_healthy', 
    'Tomato_Late_Blight', 'Tomato_Leaf_Mold', 'Tomato_Mosaic_Virus', 
    'Tomato_Septoria_Leaf_Spot', 'Tomato_Target_Spot', 'Tomato_Two_Spotted_Spider_Mite', 
    'Tomato_Yellow_Leaf_Curl_Virus', 'Wheat_Crown_and_Root_Rot', 'Wheat_healthy', 
    'Wheat_Leaf_Rust', 'Wheat_Loose_Smut'
]
CLASS_NAMES = sorted(raw_classes)
NUM_CLASSES = len(CLASS_NAMES)

# çŠ¶æ€æ ‡å¿—ä½
IS_TRAINING = False 

# ================= 2. æ¨¡å‹åˆå§‹åŠ è½½ =================
app = Flask(__name__)

def load_network_structure():
    """å®šä¹‰ç½‘ç»œç»“æ„ï¼Œæ–¹ä¾¿å¤ç”¨"""
    net = resnet50(weights=None)
    num_ftrs = net.fc.in_features
    net.fc = torch.nn.Linear(num_ftrs, NUM_CLASSES)
    return net

print(f"ğŸ”„ åˆå§‹åŒ–åŠ è½½æ¨¡å‹...")
model = load_network_structure()
# ä¼˜å…ˆåŠ è½½ Best æ¨¡å‹ï¼ˆå¦‚æœæœ‰ï¼‰ï¼Œå¦åˆ™åŠ è½½åˆå§‹ v1 æ¨¡å‹
current_weights = BEST_MODEL_PATH if os.path.exists(BEST_MODEL_PATH) else MODEL_PATH
try:
    model.load_state_dict(torch.load(current_weights, map_location=DEVICE))
    model.to(DEVICE)
    model.eval()
    print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {current_weights}")
except Exception as e:
    print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")

# é¢„å¤„ç† (ä¿æŒè®­ç»ƒå’Œæ¨ç†ä¸€è‡´)
inference_transform = T.Compose([
    T.Resize(256),T.CenterCrop(224),T.ToTensor(),
    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])
train_transform = T.Compose([
    T.RandomResizedCrop(224),T.RandomHorizontalFlip(),T.ToTensor(),
    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# ================= 3. åå°è®­ç»ƒé€»è¾‘ (æ ¸å¿ƒ) =================

def train_task_thread():
    """åå°è®­ç»ƒçº¿ç¨‹å‡½æ•°"""
    global IS_TRAINING, model
    print("\nğŸš€ [Background] è§¦å‘é‡è®­ç»ƒä»»åŠ¡ started...")
    IS_TRAINING = True
    
    try:
        # A. å‡†å¤‡æ•°æ®
        # 1. åŸå§‹æ•°æ®é›†
        original_dataset = datasets.ImageFolder(ORIGINAL_DATASET_DIR, transform=train_transform)
        # 2. åé¦ˆæ•°æ®é›† (æœ¬æ¬¡ç§¯æ”’çš„100å¼ )
        feedback_dataset = datasets.ImageFolder(FEEDBACK_DIR, transform=train_transform)
        
        # 3. æ··åˆæ•°æ® (é˜²æ­¢é—å¿˜)
        combined_dataset = ConcatDataset([original_dataset, feedback_dataset])
        train_loader = DataLoader(combined_dataset, batch_size=16, shuffle=True, num_workers=0) 
        # æ³¨æ„: num_workers=0 æ˜¯ä¸ºäº†é˜²æ­¢å¤šè¿›ç¨‹åœ¨Flaskä¸­æŠ¥é”™ï¼Œè™½ç„¶ä¼šæ…¢ä¸€ç‚¹ä½†æ›´ç¨³
        
        # B. å‡†å¤‡æ–°æ¨¡å‹è¿›è¡Œè®­ç»ƒ
        # è¿™æ˜¯ä¸€ä¸ªæŠ€å·§ï¼šæˆ‘ä»¬å¤åˆ¶å½“å‰æ¨¡å‹çš„å‚æ•°ä½œä¸ºèµ·ç‚¹ï¼Œè€Œä¸æ˜¯ä»å¤´éšæœºåˆå§‹åŒ–
        new_model = load_network_structure()
        new_model.load_state_dict(model.state_dict()) # ç»§æ‰¿å½“å‰â€œæ™ºæ…§â€
        new_model.to(DEVICE)
        new_model.train()

        criterion = torch.nn.CrossEntropyLoss()
        # å­¦ä¹ ç‡è®¾å°ä¸€ç‚¹ (LR=0.0001)ï¼Œå› ä¸ºåªæ˜¯å¾®è°ƒï¼Œä¸æƒ³å¤§å¹…éœ‡è¡
        optimizer = torch.optim.Adam(new_model.parameters(), lr=0.0001)

        print(f"ğŸ“‰ [Background] å¼€å§‹è®­ç»ƒï¼Œæ€»æ•°æ®é‡: {len(combined_dataset)}ï¼Œè®¡åˆ’è®­ç»ƒ 3 Epochs...")
        
        # C. è®­ç»ƒå¾ªç¯ (ç®€åŒ–ç‰ˆï¼Œåªè·‘3-5è½®å³å¯)
        EPOCHS = 3
        for epoch in range(EPOCHS):
            running_loss = 0.0
            steps = 0
            for inputs, labels in train_loader:
                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)
                optimizer.zero_grad()
                outputs = new_model(inputs)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()
                running_loss += loss.item()
                steps += 1
                
                if steps % 10 == 0:
                    print(f"   [Epoch {epoch+1}] Step {steps}, Loss: {loss.item():.4f}")
            
            print(f"âœ… [Epoch {epoch+1} Done] Avg Loss: {running_loss/steps:.4f}")

        # D. ä¿å­˜æ–°æ¨¡å‹
        torch.save(new_model.state_dict(), BEST_MODEL_PATH)
        print(f"ğŸ’¾ [Background] æ–°æ¨¡å‹å·²ä¿å­˜è‡³: {BEST_MODEL_PATH}")

        # E. çƒ­æ›´æ–° (Hot Reload) !!! æ ¸å¿ƒä»£ç  !!!
        # åœ¨ä¸»çº¿ç¨‹ä½¿ç”¨æ–°æ¨¡å‹ä¹‹å‰ï¼Œæˆ‘ä»¬åœ¨å†…å­˜ä¸­ç›´æ¥æ›¿æ¢å˜é‡
        model.load_state_dict(new_model.state_dict())
        model.eval()
        print("ğŸ”„ [Background] å…¨å±€æ¨¡å‹å¼•ç”¨å·²æŒ‡å‘æ–°è®­ç»ƒçš„æƒé‡ (Hot Reload Completed!)")

        # F. æ•°æ®å½’æ¡£ (å¯é€‰)
        # è®­ç»ƒå®Œäº†ï¼ŒæŠŠ feedback_data é‡Œçš„å›¾ç‰‡ç§»åˆ° archive å»ï¼Œæ¸…ç©ºè®¡æ•°å™¨
        timestamp = int(time.time())
        archive_dest = os.path.join(ARCHIVE_DIR, str(timestamp))
        shutil.move(FEEDBACK_DIR, archive_dest)
        os.makedirs(FEEDBACK_DIR, exist_ok=True) # é‡å»ºç©ºç›®å½•
        print(f"ğŸ“¦ [Background] åé¦ˆæ•°æ®å·²å½’æ¡£è‡³ {archive_dest}")

    except Exception as e:
        print(f"âŒ [Background] è®­ç»ƒä»»åŠ¡å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        IS_TRAINING = False
        print("ğŸ [Background] è®­ç»ƒä»»åŠ¡ç»“æŸã€‚\n")

def check_and_trigger_retrain():
    """æ£€æŸ¥æ˜¯å¦æ»¡è¶³è®­ç»ƒæ¡ä»¶"""
    if IS_TRAINING:
        print("âš ï¸ æ­£åœ¨è®­ç»ƒä¸­ï¼Œè·³è¿‡æœ¬æ¬¡è§¦å‘æ£€æŸ¥ã€‚")
        return

    # ç»Ÿè®¡ feedback_data æ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰å›¾ç‰‡æ•°é‡
    count = 0
    for root, dirs, files in os.walk(FEEDBACK_DIR):
        count += len([f for f in files if f.endswith(('.jpg', '.png', '.jpeg'))])
    
    print(f"ğŸ“Š å½“å‰åé¦ˆæ± ç§¯ç´¯å›¾ç‰‡æ•°: {count} / é˜ˆå€¼: {RETRAIN_THRESHOLD}")
    
    if count >= RETRAIN_THRESHOLD:
        # å¯åŠ¨æ–°çº¿ç¨‹
        t = threading.Thread(target=train_task_thread)
        t.start()
        return True
    return False

# ================= 4. API è·¯ç”± =================

@app.route('/predict', methods=['POST'])
def predict():
    """
    æ¥æ”¶å›¾ç‰‡æµ -> å†…å­˜å¤„ç† -> é¢„æµ‹ -> è¿”å›JSON
    æ³¨æ„ï¼šè¿™é‡Œä¸å†ä¿å­˜ä¸´æ—¶æ–‡ä»¶åˆ° uploads æ–‡ä»¶å¤¹ï¼Œé€Ÿåº¦æ›´å¿«
    """
    if 'file' not in request.files:
        return jsonify({'error': 'No file part'}), 400
    
    file = request.files['file']
    if file.filename == '':
        return jsonify({'error': 'No selected file'}), 400

    try:
        # A. è¯»å–æ–‡ä»¶åˆ°å†…å­˜
        img_bytes = file.read()
        image = Image.open(io.BytesIO(img_bytes)).convert('RGB')
        
        # B. é¢„å¤„ç†
        img_tensor = transform(image).unsqueeze(0).to(DEVICE)
        
        # C. æ¨ç†
        with torch.no_grad():
            outputs = model(img_tensor)
            probabilities = torch.nn.functional.softmax(outputs, dim=1)
            confidence, predicted_idx = torch.max(probabilities, 1)

        result_class = CLASS_NAMES[predicted_idx.item()]
        confidence_score = float(confidence.item())

        # D. è¿”å›ç»“æœ
        return jsonify({
            'prediction': {
                'class_name': result_class,
                'confidence': float(f"{confidence_score:.4f}")
            },
            'status': 'success'
        })

    except Exception as e:
        print(f"Prediction Error: {e}")
        return jsonify({'error': str(e)}), 500
        
    # è®°å¾—å¼•ç”¨å…¨å±€çš„ model (å®ƒå¯èƒ½ä¼šè¢«åå°çº¿ç¨‹æ›´æ–°)
    if 'file' not in request.files: return jsonify({'error': 'No file'}), 400
    file = request.files['file']
    try:
        img_bytes = file.read()
        image = Image.open(io.BytesIO(img_bytes)).convert('RGB')
        img_tensor = inference_transform(image).unsqueeze(0).to(DEVICE)
        
        with torch.no_grad():
            outputs = model(img_tensor) # è¿™é‡Œè°ƒç”¨çš„ model æ€»æ˜¯æœ€æ–°çš„
            probs = torch.nn.functional.softmax(outputs, dim=1)
            conf, idx = torch.max(probs, 1)
            
        return jsonify({
            'prediction': {'class_name': CLASS_NAMES[idx.item()], 'confidence': float(conf.item())},
            'status': 'success',
            'model_version': 'latest' # å¯ä»¥æ ‡è®°ä¸€ä¸‹
        })
    except Exception as e: return jsonify({'error': str(e)}), 500

@app.route('/feedback', methods=['POST'])
def save_feedback():
    if 'file' not in request.files or 'correct_label' not in request.form:
        return jsonify({"error": "Missing info"}), 400
    
    file = request.files['file']
    correct_label = request.form['correct_label']
    
    if correct_label not in CLASS_NAMES:
        return jsonify({"error": "Invalid label"}), 400

    try:
        # ä¿å­˜å›¾ç‰‡
        label_dir = os.path.join(FEEDBACK_DIR, correct_label)
        os.makedirs(label_dir, exist_ok=True)
        filename = f"{uuid.uuid4()}.jpg"
        file.save(os.path.join(label_dir, filename))
        
        # é‡ç‚¹ï¼šä¿å­˜æˆåŠŸåï¼Œç«‹å³æ£€æŸ¥æ˜¯å¦éœ€è¦è§¦å‘è®­ç»ƒ
        triggered = check_and_trigger_retrain()
        
        msg = "Feedback saved."
        if triggered:
            msg += " Retraining triggered in background!"
            
        return jsonify({"status": "success", "message": msg, "retraining": triggered})
        
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/status', methods=['GET'])
def server_status():
    """æŸ¥çœ‹æœåŠ¡å™¨å½“å‰çŠ¶æ€"""
    # ç»Ÿè®¡ feedback æ•°é‡
    count = 0
    for _, _, files in os.walk(FEEDBACK_DIR):
        count += len([f for f in files if f.endswith(('.jpg', '.png'))])
        
    return jsonify({
        "is_training": IS_TRAINING,
        "feedback_count": count,
        "feedback_threshold": RETRAIN_THRESHOLD,
        "device": str(DEVICE)
    })

if __name__ == '__main__':
    # åˆå§‹åŒ–ç›®å½•
    os.makedirs(FEEDBACK_DIR, exist_ok=True)
    os.makedirs(ARCHIVE_DIR, exist_ok=True)
    
    print(f"ğŸš€ AI Server Pro starting on port {PORT}...")
    app.run(host='0.0.0.0', port=PORT, debug=False, threaded=True) 
    # threaded=True å…è®¸å¤šä¸ªè¯·æ±‚å¹¶å‘ï¼Œé˜²æ­¢è®­ç»ƒæ—¶é˜»å¡é¢„æµ‹è¯·æ±‚
